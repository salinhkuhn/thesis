\chapter{Related Work }
This section presents work in the broader area of verified compilation as well as verification projects specifically targeting the LLVM ecosystem. We present contributions from validating single optimization passes to fully end to-end verified compilerse. In addition, we discuss previous work on the formalization of LLVM IR and ISA semantics as well as compiler testing.

\textbf{Verified Compilation}
In the past various efforts have been performed to apply formal methods to the compiler design space. We could identify two prominent approaches to exist: The first approach focuses on the implementation of new fully verified compilation infrastructures where the correctness of the compiler component is verified once and for all. This approach usually requires large manual proof effort and provides limited optimization. The second approach verifies existing mainstream compiler components through the use of translation validation techniques. Translation validation refers to certifying that an execution stage of a compiler is correct by verifying the semantic equivalence between the input and output of the individual stage.  

A prominent example of the first approach is CompCert [ Leroy et al.] an optimizing compiler for a large subset of the C programming language, ".. which is formally verified, using machine-assisted mathematical proofs, to guarantee the absence of compiler bugs."  CompCert compiles C programs into machine code for various processor targets, including RISC-V, and provides formal correctness guarantees for its compilation process. The compiler is implemented in the RCoq proof assistant and goes through 8 IR's and 15 compilation passes before outputting assembly code. Optimizations in CompCert is limited by the manual effort to provide the correct proof and constantly adapt the compiler to support the new optimization pattern without breaking existing proofs. 

For verification, CompCert based their ISA semantics on manual translations from the ISA specification into RCoq. There is no indication that CompCert integrates external machine-checked ISA models, such as those generated from the Sail language. In this regard, our work provides correctness proofs that our RISC-V semantics correspond to the machine-formalized semantics accepted by RISC-V International. Due to its limited optimization support, CompCert has been relegated to specialized contexts where full correctness is safety-critical. In contrast, Alive is a project that has gained wide spread acceptance within the LLVM ecosystem and showcases that verification and automation within the mainstream compiler design space is possible, useable and accepted by compiler developers. Alive provides a tool to automatically verify the correctness of LLVM IR optimizations. It checks the input and output for refinement using an SMT solver for verification. Alive can miss bugs in certain circumstances as it is a bounded translation validation tool e.g. sets an upper bound to unfolding loops. Bugs that would be exposed by continuously unfolding are missed. Therefore as stated in their paper, "there are certain circumstances in which it misses bugs". 

\textbf{Verified Peephole Optimization}
Assembly-level peephole transformations are common in compilers and are known to be particularly bug-prone. [quote peek paper] Various efforts have been made to verify and implement local rewrite patterns and ensure their correctness. One effort is Peek, a framework for expressing, verifying, and executing machine code transformations for x86 within CompCert. However, Peek requires the peephole rewrite patterns to be linear and adjacent. Contrary to the peephole hole rewriter in Lean-MLIR, which can optimize across non-linear instruction sequences interleaved with unrelated instructions. Peek explicitly models side effects and includes a memory-related rewrites. Similar to our work, Peek reasons that applying locally semantics-preserving rewrites preserves the global meaning of the program.

Additional work on verifying peephole optimizations was conducted by the Lean-MLIR project [7], which is discussed in detail in a dedicated section. In particular, Lean-MLIR formalized and verified several of the peephole rewrites used in InstCombine, a widely-used LLVM IR optimization pass. Alive also provides a verification tool for LLVM's peephole optimizations while AliveInLean is a reimplementation of the project in Lean. There have been verification efforts for peephole optimizations in other programing languages.  [] developed a verification tool for rewrites in Halide. 
[https://arxiv.org/pdf/2407.03685,
https://coqpl.cs.washington.edu/wp-content/uploads/2014/12/peek.pdf
]

\textbf{Lean-MLIR}
We mention lean-MLIR in this section to highlight the related projects built with Lean-MLIR, while details of the framework itself are covered in Chapter 3. Tobias et Al. published a paper on “Verifying Peephole Rewrites in SSA Compiler IRs” introducing Lean-MLIR framework and derived projects from it. The Lean-MLIR framework was used to reimplement and formally verify 93 test cases from Alive2, which demonstrated the use of Lean-MLIR to real world compiler optimization patterns. Using Lean-MLIR to verify the test cases used in Alive exposed xy bugs.  At the time of this thesis, Lean-MLIR had been used to formulate and verify rewrites within single IR's such as LLVM IR. However, Lean-MLIR has not been extended to support cross-dialect transformations or used to model hardware-level assembly IR's. This gave the potential to further develop the work in the direction of dialect lowerings and low-level language optimizations. Inspired by this we extend the application of Lean-MLIR and its verification methodology across multiple layers of a compiler pipeline, by adding a instruction selection pass and machine-level transformations. Other efforts on Lean-MLIR have formalized various dialects, including one for fully homomorphic encryption. Additionally, the authors of Lean-MLIR have conducted research on effective automation for bit-vector reasoning, which is essential for discharging proof goals in programs that use bit vectors as their semantic model.

\textbf{Formal Semantics of LLVM IR}
The formalization of LLVM IR semantics has been at focus of several research. Verification tools like Alive have found bugs in LLVM that stem from simple logical implementation errors. Besides the typical logical implementation errors, there are bugs caused by underspecification of the LLVM IR semantics which leads to different interpretations of certain instructions in a given context. To build verification tools and distinguish miscompilations from correct compilations,  consensus on the specification of LLVM IR is needed. The intended semantics of LLVM IR are documented online in the reference manual but are not exhaustive and do not provide a  rigourous mathematically formalization of the semantics. Given the size and high activity of the LLVM community, there exist a lack of coordination on the accepted semantics of LLVM IR, and any discrepancy in how semantics are interpreted leads to subtle bugs, as history has shown [Alive paper]. Vellvm is one effort to formalize the semantics of LLVM IR and provides a framework for reasoning about LLVM IR programs. Unlike our work, Vellvm is implemented in the Coq theorem prover and uses a definition of refinement that differs from the one used in this thesis.  We also do not adopt the semantics formalized in Vellvm because they do not satisfy the monotonicity property that we believe should hold. Similar to our work, Vellvm does not support all forms of UB e.g. they fix all undef values to a zero initializer. Besides Vellvm, the authors of Alive provide a formalization of LLVM IR in their paper. Alive interacted with the LLVM community to iterate over underspecified parts and reached consensus on how to fix discrepancies in the LLVM IR semantics—e.g., how the select instruction interacts with poison values. This work performed by Alive is relevant to our own, since our semantic model provided by Lean-MLIR is close to the Alive formalization except for the mentioned UB. The semantics of UB have been explored in [taming UB paper] and proposed changes adapted by LLVM.  For any formal methods efforts in the LLVM ecosystem, formalizations of LLVM IR are crucial and therefore we mention this work in this section. 

[taming udef by hjohn regehr, vellvm, alive ]
[https://dl.acm.org/doi/pdf/10.1145/2103621.2103709]


\textbf{Compiler testing and fuzzing}
Besides formal verification, which provides strong correctness guarantees and can prove the absence of bugs, as demonstrated in CompCert, testing and fuzzing tools have been highly effective in identifying compiler bugs. Several bugs in the optimizers of commercial compilers, including LLVM, have been discovered by tools such as those described in [citation].

[to do: add further work on this]
[to do: formally show where Vellvm's semantics fail this].
[to do: extend with a more in depth disccusion on work on the semantics]
[https://dl.acm.org/doi/pdf/10.1145/2103621.2103709]
[TO DO check vellvm refinement statement]

